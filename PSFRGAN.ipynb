{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSFRGAN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9vf9e8xGCXd"
      },
      "source": [
        "### CUDA info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_H1UkrGF5D1"
      },
      "source": [
        "import torch\n",
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6MoweKYGE7l"
      },
      "source": [
        "### Cloning repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4yNMRfgisRZ",
        "outputId": "a22972f3-2ce4-4514-c447-49dd3e06c683"
      },
      "source": [
        "! git clone https://BertyWooster:PASSWORD@github.com/BertyWooster/PSFRGAN_COPY.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PSFRGAN_COPY'...\n",
            "remote: Enumerating objects: 213, done.\u001b[K\n",
            "remote: Counting objects: 100% (213/213), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 213 (delta 40), reused 208 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (213/213), 2.80 MiB | 10.73 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNZNf0IIi0rO",
        "outputId": "e50d2bad-ded2-4be2-c77e-98394bbc8a44"
      },
      "source": [
        "%cd /content/PSFRGAN_COPY/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PSFRGAN_COPY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LekgjLwii6HJ"
      },
      "source": [
        "! pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k702MgptGH-V"
      },
      "source": [
        "### Loading wghts and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmEEuZPijks1"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1UhzMSORSul88iVfSYQYuEal83lEoNN7l',\n",
        "                                    dest_path='/content/PSFRGAN_COPY/pretrain_models/mmod_human_face_detector.dat',\n",
        "                                    unzip=False)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1UiHeUHVNKiEq_s5dcBv6jez6TqrAduMg',\n",
        "                                    dest_path='/content/PSFRGAN_COPY/pretrain_models/shape_predictor_5_face_landmarks.dat',\n",
        "                                    unzip=False)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1UcTeI_-YmQeNypHW98VRuIF13xEPmPWm',\n",
        "                                    dest_path='/content/PSFRGAN_COPY/pretrain_models/FFHQ_template.npy',\n",
        "                                    unzip=False)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1Uxb-nw04fyjABEaZCgeYgGrR4fIu7VUf',\n",
        "                                    dest_path='/content/PSFRGAN_COPY/pretrain_models/psfrgan_latest_net_G.pth',\n",
        "                                    unzip=False)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1Unn2eznkclqUhK_o50YUyaV7eoTE4Su3',\n",
        "                                    dest_path='/content/PSFRGAN_COPY/pretrain_models/parse_multi_iter_90000.pth',\n",
        "                                    unzip=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ0lyMDb4fFo"
      },
      "source": [
        "# load test data\n",
        "\n",
        "! mkdir /content/test_data/\n",
        "! mkdir /content/test_data/vid/\n",
        "\n",
        "mkt_file_ID = \"1oYSyd_6CCZrmQoZ15WRjEQoJtiQY8YPo\"\n",
        "mkt_fo_static_file_ID = \"1w2kVvWLpQD6CkjeINxxt_WUv4oYVC3MB\"\n",
        "mkt_fo_active_file_ID = \"1zTQ8t-xyGEaDuOm6Z1Pc4_ezMIhS6wZ2\"\n",
        "mkt_fo_active_file_512_ID = \"1wBAcpnYrYStpUfi1A_pV0nJvlQmKmdLQ\"\n",
        "start_ID = \"1q0P6o7ucKYBjSNK8P5_6QIPM5iXD_tJl\"\n",
        "\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id=mkt_file_ID,\n",
        "                                    dest_path='/content/test_data/vid/mkt.mp4',\n",
        "                                    unzip=False)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id=mkt_fo_static_file_ID,\n",
        "                                    dest_path='/content/test_data/vid/mkt_fo_static.mp4',\n",
        "                                    unzip=False)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id=mkt_fo_active_file_ID,\n",
        "                                    dest_path='/content/test_data/vid/mkt_fo_active.mp4',\n",
        "                                    unzip=False)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id=mkt_fo_active_file_512_ID,\n",
        "                                    dest_path='/content/test_data/vid/mkt_fo_active_512.mp4',\n",
        "                                    unzip=False)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id=start_ID,\n",
        "                                    dest_path='/content/test_data/vid/start.mp4',\n",
        "                                    unzip=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFQRaEmGn2J9"
      },
      "source": [
        "### Краткий пайплайн покадровой обработки - по скорости не оптимизирован"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUdOcFRWoYjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5555f5b-a6ed-4d83-f6cb-ae728db96b9a"
      },
      "source": [
        "%cd /content/PSFRGAN_COPY/\n",
        "from tqdm import tqdm\n",
        "import dlib\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "from skimage import transform as trans\n",
        "from skimage import io\n",
        "\n",
        "import time\n",
        "import torch\n",
        "from utils import utils\n",
        "from options.test_options import TestOptions\n",
        "from models import create_model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/PSFRGAN_COPY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UurTfd0Rn_PL"
      },
      "source": [
        "# functions \n",
        "\n",
        "def detect_and_align_faces(img, face_detector, lmk_predictor, template_path, template_scale=2, size_threshold=999):\n",
        "    align_out_size = (512, 512)\n",
        "    ref_points = np.load(template_path) / template_scale\n",
        "        \n",
        "    # Detect landmark points\n",
        "    face_dets = face_detector(img, 1)\n",
        "    assert len(face_dets) > 0, 'No faces detected'\n",
        "\n",
        "    aligned_faces = []\n",
        "    tform_params = []\n",
        "    for det in face_dets:\n",
        "        if isinstance(face_detector, dlib.cnn_face_detection_model_v1):\n",
        "            rec = det.rect # for cnn detector\n",
        "        else:\n",
        "            rec = det\n",
        "        if rec.width() > size_threshold or rec.height() > size_threshold: \n",
        "            print('Face is too large')\n",
        "            break\n",
        "        landmark_points = lmk_predictor(img, rec) \n",
        "        single_points = []\n",
        "        for i in range(5):\n",
        "            single_points.append([landmark_points.part(i).x, landmark_points.part(i).y])\n",
        "        single_points = np.array(single_points)\n",
        "        tform = trans.SimilarityTransform()\n",
        "        tform.estimate(single_points, ref_points)\n",
        "        tmp_face = trans.warp(img, tform.inverse, output_shape=align_out_size, order=3)\n",
        "        aligned_faces.append(tmp_face*255)\n",
        "        tform_params.append(tform)\n",
        "    return [aligned_faces, tform_params]\n",
        "\n",
        "class Opt:\n",
        "  def __init__(self):\n",
        "    self.model = \"enhance\"\n",
        "    self.device = \"cuda\"\n",
        "    self.gpu_ids = [0]\n",
        "    self.isTrain = False\n",
        "    self.checkpoints_dir = \"./check_points\"\n",
        "    self.name = \"experiment_name\"\n",
        "    self.Pnorm = \"bn\"\n",
        "    self.data_device = \"cuda\"\n",
        "    self.Gin_size = 512\n",
        "    self.Gout_size = 512\n",
        "    self.Gnorm = 'spade'\n",
        "    self.D_num = 3\n",
        "    self.parse_net_weight = \"./pretrain_models/parse_multi_iter_90000.pth\"\n",
        "    self.psfr_net_weight = \"./pretrain_models/psfrgan_latest_net_G.pth\"\n",
        "\n",
        "\n",
        "def def_models():\n",
        "    opt = Opt()\n",
        "    model = create_model(opt)\n",
        "    model.load_pretrain_models()\n",
        "    model.netP.to(opt.device)\n",
        "    model.netG.to(opt.device)\n",
        "    return model\n",
        "\n",
        "\n",
        "def enhance_faces(LQ_faces, model):\n",
        "    hq_faces = []\n",
        "    lq_parse_maps = []\n",
        "    for lq_face in tqdm(LQ_faces):\n",
        "        with torch.no_grad():\n",
        "            lq_tensor = torch.tensor(lq_face.transpose(2, 0, 1)) / 255. * 2 - 1\n",
        "            lq_tensor = lq_tensor.unsqueeze(0).float().to(model.device)\n",
        "            parse_map, _ = model.netP(lq_tensor)\n",
        "            parse_map_onehot = (parse_map == parse_map.max(dim=1, keepdim=True)[0]).float()\n",
        "            _, output_SR = model.netG(lq_tensor, parse_map_onehot)\n",
        "        hq_faces.append(utils.tensor_to_img(output_SR))\n",
        "        lq_parse_maps.append(utils.color_parse_map(parse_map_onehot)[0])\n",
        "    return hq_faces, lq_parse_maps\n",
        "\n",
        "\n",
        "def past_faces_back(img, hq_faces, tform_params, upscale=1):\n",
        "    h, w = img.shape[:2]\n",
        "    img = cv2.resize(img, (int(w*upscale), int(h*upscale)), interpolation=cv2.INTER_CUBIC)\n",
        "    for hq_img, tform in tqdm(zip(hq_faces, tform_params), total=len(hq_faces)):\n",
        "        tform.params[0:2,0:2] /= upscale\n",
        "        back_img = trans.warp(hq_img/255., tform, output_shape=[int(h*upscale), int(w*upscale)], order=3) * 255\n",
        "        \n",
        "        # blur mask to avoid border artifacts\n",
        "        mask = (back_img == 0) \n",
        "        mask = cv2.blur(mask.astype(np.float32), (5,5))\n",
        "        mask = (mask > 0)\n",
        "        img = img * mask + (1 - mask) * back_img \n",
        "    return img.astype(np.uint8)\n",
        "\n",
        "\n",
        "def save_imgs(img_list, save_dir):\n",
        "    for idx, img in enumerate(img_list):\n",
        "        save_path = os.path.join(save_dir, '{:03d}.jpg'.format(idx))\n",
        "        io.imsave(save_path, img.astype(np.uint8))\n",
        "\n",
        "class VideoProcesser:\n",
        "  def __init__(self):\n",
        "    self.working_dir = \"/content/w_dir/\"\n",
        "    self.res_dir = \"/content/results/\"\n",
        "    self.face_detector = dlib.cnn_face_detection_model_v1('./pretrain_models/mmod_human_face_detector.dat')\n",
        "    self.lmk_predictor = dlib.shape_predictor('./pretrain_models/shape_predictor_5_face_landmarks.dat')\n",
        "    self.template_path = './pretrain_models/FFHQ_template.npy'\n",
        "    self.enhance_model = def_models()\n",
        "    os.system(\"mkdir \" + self.working_dir)\n",
        "    os.system(\"mkdir \" + self.res_dir)\n",
        "  \n",
        "  def read_vid(self, vid_path, to_512=False):\n",
        "    self.v_name = vid_path.split(\"/\")[-1]\n",
        "    os.system(\"cp \" + vid_path + \" \" + self.working_dir)\n",
        "    if to_512:\n",
        "      os.system(\"ffmpeg -i \" + self.working_dir + self.v_name + \" -vf scale=512:512 \" + self.working_dir + \"tmp.mp4\")\n",
        "      os.system(\"rm -rf \" + self.working_dir + self.v_name)\n",
        "      os.system(\"mv \" + self.working_dir + \"tmp.mp4 \" + self.working_dir + self.v_name)\n",
        "\n",
        "  def preprocess(self):\n",
        "    os.system(\"ffmpeg -i \" + self.working_dir + self.v_name + \" \" + self.working_dir + \"%d.jpg\")\n",
        "    os.system(\"ffmpeg -i \" + self.working_dir + self.v_name + \" \" + self.working_dir + self.v_name[:-4] + \".wav\")\n",
        "\n",
        "  def process(self):\n",
        "    align_time = []\n",
        "    enhance_time = []\n",
        "    n_frames = [x for x in os.listdir(self.working_dir) if x.count(\".jpg\")==1]\n",
        "    for i in tqdm(range(len(n_frames))):\n",
        "      im_name = str(i+1)+\".jpg\"\n",
        "      img = dlib.load_rgb_image(self.working_dir + im_name)\n",
        "      \n",
        "      t_al1 = time.time()\n",
        "      aligned_faces, tform_params = detect_and_align_faces(img, self.face_detector, self.lmk_predictor, self.template_path)\n",
        "      t_al2 = time.time()\n",
        "      align_time.append(t_al2-t_al1)\n",
        "\n",
        "      t_en1 = time.time()\n",
        "      hq_faces, lq_parse_maps = enhance_faces(aligned_faces, self.enhance_model)\n",
        "      t_en2 = time.time()\n",
        "      enhance_time.append(t_en2-t_en1)\n",
        "\n",
        "      hq_img = past_faces_back(img, hq_faces, tform_params, upscale=1)\n",
        "      final_save_path = self.res_dir+im_name\n",
        "      io.imsave(final_save_path, hq_img) \n",
        "      # TODO here you have to set orig fps\n",
        "    os.system(\"ffmpeg -framerate 30 -i \" + self.res_dir + \"%d.jpg \" + self.res_dir + \"p_\" + self.v_name)\n",
        "    os.system(\"ffmpeg -i \" + self.res_dir + \"p_\" + self.v_name + \" -i \" + self.working_dir + self.v_name[:-4]+'.wav' + \" \" + self.res_dir + \"fp_\" + self.v_name)\n",
        "    os.system(\"rm -rf \" + self.res_dir + \"*.jpg*\")\n",
        "    align_mean = np.mean(np.array(align_time))\n",
        "    align_sum = np.sum(np.array(align_time))\n",
        "    enhance_mean = np.mean(np.array(enhance_time))\n",
        "    enhance_sum = np.sum(np.array(enhance_time))\n",
        "    print(\"align fps ±\", 1./align_mean)\n",
        "    print(\"total align is\", align_sum)\n",
        "    print(\"enhance fps ±\", 1./enhance_mean)\n",
        "    print(\"enhance align is\", enhance_sum)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4q8_x-MA7FC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b36b7ec-cde2-4e43-dafb-a7f5899d722c"
      },
      "source": [
        "%%time\n",
        "# ! rm -rf /content/w_dir\n",
        "# ! rm -rf /content/results"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.22 ms, sys: 52.6 ms, total: 56.8 ms\n",
            "Wall time: 316 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te2fVUeTGVKv"
      },
      "source": [
        "### set vid path and process it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B29MqikhspPu"
      },
      "source": [
        "%cd /content/PSFRGAN_COPY/\n",
        "processor = VideoProcesser()\n",
        "processor.read_vid('/content/test_data/vid/start.mp4', to_512=True)\n",
        "processor.preprocess()\n",
        "processor.process()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}